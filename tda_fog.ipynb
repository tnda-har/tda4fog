{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from numpy import interp\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gtda.diagrams import Scaler, PersistenceEntropy, BettiCurve, PersistenceLandscape, Silhouette\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "from gtda.pipeline import make_pipeline\n",
    "from gtda.time_series import SlidingWindow, TakensEmbedding\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_prefog(dataset,window_length = 1):#一般步长都是一到4\n",
    "  dataset.drop(index = list(dataset[dataset['Action'] == 0].index),inplace=True)#axis删除行，默认为0,删除列默认为1，index直接指定要删除的行，inplace为真则删除数据不返回，为假则返回删除后的表\n",
    "  window_length = 64*window_length\n",
    "    \n",
    "  fog_index=[]\n",
    "  for i in dataset.index:\n",
    "      if dataset.loc[i,'Action'] == 2:#取Action列的第i行的数据等于2\n",
    "        fog_index.append(i)\n",
    "  fog_index\n",
    "\n",
    "\n",
    "\n",
    "  start_indices=[]\n",
    "  for i in fog_index:\n",
    "    if (dataset.loc[i-1,'Action']!=dataset.loc[i,'Action']):\n",
    "      start_indices.append(i)\n",
    " \n",
    "\n",
    "  prefog=[]\n",
    "  for start in start_indices:\n",
    "    prefog_start = [x for x in range(start-window_length,start)]#列表解析式一个嵌套循环\n",
    "    prefog.append(prefog_start)\n",
    "\n",
    "  prefog = [item for sublist in prefog for item in sublist]#两个循环，sublist（子表）在prefog中，item在sublist中，输出item\n",
    "\n",
    "  for i in prefog:\n",
    "       dataset.loc[i,'Action'] = 3\n",
    "  dataset['Action'] = dataset['Action'] - 1\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S01\n",
      "S01R01.txt  is read\tAdding S01R01.txt to dataset\tS01R01.txt is labelled\n",
      "\n",
      "S01\n",
      "S01R02.txt  is read\tAdding S01R02.txt to dataset\tS01R02.txt is labelled\n",
      "\n",
      "S02\n",
      "S02R01.txt  is read\tAdding S02R01.txt to dataset\tS02R01.txt is labelled\n",
      "\n",
      "S02\n",
      "S02R02.txt  is read\tAdding S02R02.txt to dataset\tS02R02.txt is labelled\n",
      "\n",
      "S03\n",
      "S03R01.txt  is read\tAdding S03R01.txt to dataset\tS03R01.txt is labelled\n",
      "\n",
      "S03\n",
      "S03R02.txt  is read\tAdding S03R02.txt to dataset\tS03R02.txt is labelled\n",
      "\n",
      "S03\n",
      "S03R03.txt  is read\t\n",
      "S04\n",
      "S04R01.txt  is read\t\n",
      "S05\n",
      "S05R01.txt  is read\tAdding S05R01.txt to dataset\tS05R01.txt is labelled\n",
      "\n",
      "S05\n",
      "S05R02.txt  is read\tAdding S05R02.txt to dataset\tS05R02.txt is labelled\n",
      "\n",
      "S06\n",
      "S06R01.txt  is read\tAdding S06R01.txt to dataset\tS06R01.txt is labelled\n",
      "\n",
      "S06\n",
      "S06R02.txt  is read\t\n",
      "S07\n",
      "S07R01.txt  is read\tAdding S07R01.txt to dataset\tS07R01.txt is labelled\n",
      "\n",
      "S07\n",
      "S07R02.txt  is read\tAdding S07R02.txt to dataset\tS07R02.txt is labelled\n",
      "\n",
      "S08\n",
      "S08R01.txt  is read\tAdding S08R01.txt to dataset\tS08R01.txt is labelled\n",
      "\n",
      "S09\n",
      "S09R01.txt  is read\tAdding S09R01.txt to dataset\tS09R01.txt is labelled\n",
      "\n",
      "S10\n",
      "S10R01.txt  is read\t\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "data_path = './dataset/'\n",
    "\n",
    "people = []\n",
    "dataset = pd.DataFrame()\n",
    "for person in os.listdir(data_path):#返回指定路径下的文件夹\n",
    "    if '.txt' in person: \n",
    "        people.append(person)\n",
    "        \n",
    "window_length = 2\n",
    "for person in people: \n",
    "    name = person.split('R')[0]#分割R次并取序列为0的项\n",
    "    print (name)\n",
    "    file = data_path+'/'+person\n",
    "    temp = pd.read_csv(file,delimiter= \" \", header = None)\n",
    "    print (person,' is read',end = '\\t')\n",
    "    if 2 in temp[max(temp.columns)].unique():\n",
    "        print ('Adding {} to dataset'.format(person),end = '\\t')#将人加入到dataset中\n",
    "        temp.columns = ['time','A_F','A_V','A_L','L_F','L_V','L_L','T_F','T_V','T_L','Action']    \n",
    "        temp = label_prefog(temp,window_length).reset_index(drop=True)\n",
    "        temp['name'] = name\n",
    "        print ('{} is labelled'.format(person))#不指定位置，打印人名\n",
    "        dataset = pd.concat([dataset,temp],axis = 0)#数据的拼接，在axis在行上拼接，=1在列上拼接\n",
    "\n",
    "    print ('')\n",
    "dataset.reset_index(drop =True,inplace=True) #重新排列顺序\n",
    "to_path = './'\n",
    "to_name = to_path +'win_'+str(window_length)+\".csv\"\n",
    "\n",
    "dataset.to_csv(to_name,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_window(act, window_length, dataframe):\n",
    "    indices = list(dataframe[dataframe.Action == act].index)\n",
    "    groups = []\n",
    "    temp = []\n",
    "    group_count = 0\n",
    "    for i in range(len(indices)):\n",
    "        if i == len(indices) - 1:\n",
    "            temp.append(indices[i])\n",
    "            groups.append(temp)\n",
    "            temp = []\n",
    "            break\n",
    "        temp.append(indices[i])\n",
    "        if indices[i] + 1 != indices[i + 1]:\n",
    "            group_count += 1\n",
    "            groups.append(temp)\n",
    "            temp = []\n",
    "\n",
    "    fs = 64\n",
    "\n",
    "    final_dataframe = pd.DataFrame()\n",
    "    for i in groups:\n",
    "        required = math.floor(len(i) / (window_length * fs))\n",
    "\n",
    "        req_index = i[0:(required * window_length * fs)]\n",
    "\n",
    "        final_dataframe = pd.concat([final_dataframe, dataframe.iloc[req_index, :]], axis=0)\n",
    "    return final_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sbj_df(df, sbj='S01'):\n",
    "    DF0 = create_window(0, 2, df)\n",
    "    DF0 = DF0[DF0['name'] == sbj]\n",
    "    DF1 = create_window(1, 2, df)\n",
    "    DF1 = DF1[DF1['name'] == sbj]\n",
    "    DF2 = create_window(2, 2, df)\n",
    "    DF2 = DF2[DF2['name'] == sbj]\n",
    "    return DF0, DF1, DF2\n",
    "\n",
    "\n",
    "def gtda(dataframe, w=128):\n",
    "    all_data = []\n",
    "    dataframe = dataframe.drop(columns=['time', 'Action', 'name'])\n",
    "    for i in range(0, len(dataframe), w):\n",
    "        data = dataframe.iloc[i:i + w]\n",
    "        data = data.to_numpy().transpose()\n",
    "        if data.shape[1] == w:\n",
    "            all_data.append(data)\n",
    "    all_data = np.array(all_data)\n",
    "    steps = [TakensEmbedding(time_delay=5, dimension=3),\n",
    "             VietorisRipsPersistence(),\n",
    "             Scaler()\n",
    "             ]\n",
    "    tda_pipe = make_pipeline(*steps)\n",
    "    diagrams = tda_pipe.fit_transform(all_data)\n",
    "    BC = BettiCurve(n_bins=50).fit_transform(diagrams)\n",
    "    PL = PersistenceLandscape(n_bins=50).fit_transform(diagrams)\n",
    "    SL = Silhouette(n_bins=50).fit_transform(diagrams)\n",
    "\n",
    "    return np.mean(BC, axis=1), np.mean(PL, axis=1), np.mean(SL, axis=1)\n",
    "\n",
    "\n",
    "def training(x, y, sbj_name):\n",
    "    y = np.array(y)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, shuffle=True)\n",
    "    model = RandomForestClassifier(random_state=1)\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pre = model.predict(x_test)\n",
    "    print(classification_report(y_test, y_pre, digits=4))\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, y_pre)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    print('AUC:', roc_auc)\n",
    "    print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_random_list(start, stop, n):\n",
    "    '''\n",
    "    生成范围在[start,stop], 长度为n的数组.\n",
    "    区间包含左右endpoint\n",
    "    '''\n",
    "    arr = list(range(start, stop + 1))\n",
    "    shuffle_n(arr, n)\n",
    "    return arr[-n:]\n",
    "\n",
    "\n",
    "def shuffle_n(arr, n):\n",
    "    random.seed(time.time())\n",
    "    for i in range(len(arr) - 1, len(arr) - n - 1, -1):\n",
    "        j = random.randint(0, i)\n",
    "        arr[i], arr[j] = arr[j], arr[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7692    1.0000    0.8696        10\n",
      "           1     1.0000    0.7857    0.8800        14\n",
      "\n",
      "    accuracy                         0.8750        24\n",
      "   macro avg     0.8846    0.8929    0.8748        24\n",
      "weighted avg     0.9038    0.8750    0.8757        24\n",
      "\n",
      "AUC: 0.8928571428571428\n",
      "\n",
      "\n",
      "S01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8182    0.6429    0.7200        14\n",
      "           1     0.6154    0.8000    0.6957        10\n",
      "\n",
      "    accuracy                         0.7083        24\n",
      "   macro avg     0.7168    0.7214    0.7078        24\n",
      "weighted avg     0.7337    0.7083    0.7099        24\n",
      "\n",
      "AUC: 0.7214285714285714\n",
      "\n",
      "\n",
      "S01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9000    0.9474        10\n",
      "           1     0.9333    1.0000    0.9655        14\n",
      "\n",
      "    accuracy                         0.9583        24\n",
      "   macro avg     0.9667    0.9500    0.9564        24\n",
      "weighted avg     0.9611    0.9583    0.9580        24\n",
      "\n",
      "AUC: 0.9500000000000001\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9888    0.9925    0.9906       266\n",
      "           1     0.8182    0.7500    0.7826        12\n",
      "\n",
      "    accuracy                         0.9820       278\n",
      "   macro avg     0.9035    0.8712    0.8866       278\n",
      "weighted avg     0.9814    0.9820    0.9816       278\n",
      "\n",
      "AUC: 0.8712406015037594\n",
      "\n",
      "\n",
      "S02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8621    0.9259    0.8929        27\n",
      "           1     0.8947    0.8095    0.8500        21\n",
      "\n",
      "    accuracy                         0.8750        48\n",
      "   macro avg     0.8784    0.8677    0.8714        48\n",
      "weighted avg     0.8764    0.8750    0.8741        48\n",
      "\n",
      "AUC: 0.8677248677248677\n",
      "\n",
      "\n",
      "S02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8182    0.7500    0.7826        24\n",
      "           1     0.7692    0.8333    0.8000        24\n",
      "\n",
      "    accuracy                         0.7917        48\n",
      "   macro avg     0.7937    0.7917    0.7913        48\n",
      "weighted avg     0.7937    0.7917    0.7913        48\n",
      "\n",
      "AUC: 0.7916666666666666\n",
      "\n",
      "\n",
      "S02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8571    0.6429    0.7347        28\n",
      "           1     0.6296    0.8500    0.7234        20\n",
      "\n",
      "    accuracy                         0.7292        48\n",
      "   macro avg     0.7434    0.7464    0.7290        48\n",
      "weighted avg     0.7623    0.7292    0.7300        48\n",
      "\n",
      "AUC: 0.7464285714285714\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9330    0.9837    0.9577       184\n",
      "           1     0.7500    0.4091    0.5294        22\n",
      "\n",
      "    accuracy                         0.9223       206\n",
      "   macro avg     0.8415    0.6964    0.7435       206\n",
      "weighted avg     0.9134    0.9223    0.9119       206\n",
      "\n",
      "AUC: 0.6963932806324111\n",
      "\n",
      "\n",
      "S03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9487    1.0000    0.9737        37\n",
      "           1     1.0000    0.9412    0.9697        34\n",
      "\n",
      "    accuracy                         0.9718        71\n",
      "   macro avg     0.9744    0.9706    0.9717        71\n",
      "weighted avg     0.9733    0.9718    0.9718        71\n",
      "\n",
      "AUC: 0.9705882352941176\n",
      "\n",
      "\n",
      "S03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8049    1.0000    0.8919        33\n",
      "           1     1.0000    0.7895    0.8824        38\n",
      "\n",
      "    accuracy                         0.8873        71\n",
      "   macro avg     0.9024    0.8947    0.8871        71\n",
      "weighted avg     0.9093    0.8873    0.8868        71\n",
      "\n",
      "AUC: 0.8947368421052632\n",
      "\n",
      "\n",
      "S03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8919    0.9706    0.9296        34\n",
      "           1     0.9706    0.8919    0.9296        37\n",
      "\n",
      "    accuracy                         0.9296        71\n",
      "   macro avg     0.9312    0.9312    0.9296        71\n",
      "weighted avg     0.9329    0.9296    0.9296        71\n",
      "\n",
      "AUC: 0.9312400635930047\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9855    0.9903    0.9879       206\n",
      "           1     0.9394    0.9118    0.9254        34\n",
      "\n",
      "    accuracy                         0.9792       240\n",
      "   macro avg     0.9625    0.9510    0.9566       240\n",
      "weighted avg     0.9790    0.9792    0.9790       240\n",
      "\n",
      "AUC: 0.9510279840091376\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f2fc1cfb6ee7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./win_2.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msbj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubject_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mDF0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDF1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDF2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msbj_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msbj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msbj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mNOR_DF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDF0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDF2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mnor_bc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnor_pl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnor_sl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgtda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNOR_DF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-bb12c8983470>\u001b[0m in \u001b[0;36msbj_df\u001b[0;34m(df, sbj)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msbj_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msbj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'S01'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mDF0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mDF0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDF0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDF0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msbj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mDF1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-7f453cbf96c4>\u001b[0m in \u001b[0;36mcreate_window\u001b[0;34m(act, window_length, dataframe)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mreq_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequired\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mwindow_length\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mfinal_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfinal_dataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreq_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfinal_dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/packages/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    285\u001b[0m     )\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/packages/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             new_data = concatenate_block_managers(\n\u001b[0;32m--> 503\u001b[0;31m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbm_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             )\n\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/packages/anaconda3/lib/python3.6/site-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_extension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;31m# TODO(EA2D): special-casing not needed with 2D EAs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/packages/anaconda3/lib/python3.6/site-packages/pandas/core/dtypes/concat.py\u001b[0m in \u001b[0;36mconcat_compat\u001b[0;34m(to_concat, axis)\u001b[0m\n\u001b[1;32m    178\u001b[0m                 \u001b[0mto_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"object\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mto_concat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "subject_list = ['S01', 'S02', 'S03', 'S05', 'S06', 'S07', 'S08', 'S09']\n",
    "df = pd.read_csv('./win_2.csv')\n",
    "for sbj in subject_list:\n",
    "    DF0, DF1, DF2 = sbj_df(df, sbj=sbj)\n",
    "    NOR_DF = pd.concat([DF0, DF2])\n",
    "    nor_bc, nor_pl, nor_sl = gtda(NOR_DF)\n",
    "    fog_bc, fog_pl, fog_sl = gtda(DF1)\n",
    "\n",
    "    fog = [fog_bc, fog_pl, fog_sl]\n",
    "    normal = [nor_bc, nor_pl, nor_sl]\n",
    "    print(sbj)\n",
    "\n",
    "    for length, nor_feature in enumerate(normal):\n",
    "        print('{length} feature:')\n",
    "        fog_feature = fog[length]\n",
    "        idx = get_random_list(0, len(nor_feature) - 1, int(len(fog_feature) * 1))\n",
    "        nor_feature = nor_feature[idx]\n",
    "\n",
    "        X = np.concatenate([nor_feature, fog_feature], axis=0)\n",
    "        Y = []\n",
    "        Y += len(nor_feature) * [0]\n",
    "        Y += len(fog_feature) * [1]\n",
    "\n",
    "        # x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, shuffle=True)\n",
    "        training(X, Y, sbj)\n",
    "\n",
    "    all_fog = np.concatenate(fog, axis=1)\n",
    "    all_nor = np.concatenate(normal, axis=1)\n",
    "    all_X = np.concatenate([all_nor, all_fog], axis=0)\n",
    "    all_Y = []\n",
    "    all_Y += len(all_nor) * [0]\n",
    "    all_Y += len(all_fog) * [1]\n",
    "    print('feature union')\n",
    "    training(all_X, all_Y, sbj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
