{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from numpy import interp\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gtda.diagrams import Scaler, PersistenceEntropy, BettiCurve, PersistenceLandscape, Silhouette\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "from gtda.pipeline import make_pipeline\n",
    "from gtda.time_series import SlidingWindow, TakensEmbedding\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_prefog(dataset,window_length = 1):#一般步长都是一到4\n",
    "  dataset.drop(index = list(dataset[dataset['Action'] == 0].index),inplace=True)#axis删除行，默认为0,删除列默认为1，index直接指定要删除的行，inplace为真则删除数据不返回，为假则返回删除后的表\n",
    "  window_length = 64*window_length\n",
    "    \n",
    "  fog_index=[]\n",
    "  for i in dataset.index:\n",
    "      if dataset.loc[i,'Action'] == 2:#取Action列的第i行的数据等于2\n",
    "        fog_index.append(i)\n",
    "  fog_index\n",
    "\n",
    "\n",
    "\n",
    "  start_indices=[]\n",
    "  for i in fog_index:\n",
    "    if (dataset.loc[i-1,'Action']!=dataset.loc[i,'Action']):\n",
    "      start_indices.append(i)\n",
    " \n",
    "\n",
    "  prefog=[]\n",
    "  for start in start_indices:\n",
    "    prefog_start = [x for x in range(start-window_length,start)]#列表解析式一个嵌套循环\n",
    "    prefog.append(prefog_start)\n",
    "\n",
    "  prefog = [item for sublist in prefog for item in sublist]#两个循环，sublist（子表）在prefog中，item在sublist中，输出item\n",
    "\n",
    "  for i in prefog:\n",
    "       dataset.loc[i,'Action'] = 3\n",
    "  dataset['Action'] = dataset['Action'] - 1\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S01\n",
      "S01R01.txt  is read\tAdding S01R01.txt to dataset\tS01R01.txt is labelled\n",
      "\n",
      "S01\n",
      "S01R02.txt  is read\tAdding S01R02.txt to dataset\tS01R02.txt is labelled\n",
      "\n",
      "S02\n",
      "S02R01.txt  is read\tAdding S02R01.txt to dataset\tS02R01.txt is labelled\n",
      "\n",
      "S02\n",
      "S02R02.txt  is read\tAdding S02R02.txt to dataset\tS02R02.txt is labelled\n",
      "\n",
      "S03\n",
      "S03R01.txt  is read\tAdding S03R01.txt to dataset\tS03R01.txt is labelled\n",
      "\n",
      "S03\n",
      "S03R02.txt  is read\tAdding S03R02.txt to dataset\tS03R02.txt is labelled\n",
      "\n",
      "S03\n",
      "S03R03.txt  is read\t\n",
      "S04\n",
      "S04R01.txt  is read\t\n",
      "S05\n",
      "S05R01.txt  is read\tAdding S05R01.txt to dataset\tS05R01.txt is labelled\n",
      "\n",
      "S05\n",
      "S05R02.txt  is read\tAdding S05R02.txt to dataset\tS05R02.txt is labelled\n",
      "\n",
      "S06\n",
      "S06R01.txt  is read\tAdding S06R01.txt to dataset\tS06R01.txt is labelled\n",
      "\n",
      "S06\n",
      "S06R02.txt  is read\t\n",
      "S07\n",
      "S07R01.txt  is read\tAdding S07R01.txt to dataset\tS07R01.txt is labelled\n",
      "\n",
      "S07\n",
      "S07R02.txt  is read\tAdding S07R02.txt to dataset\tS07R02.txt is labelled\n",
      "\n",
      "S08\n",
      "S08R01.txt  is read\tAdding S08R01.txt to dataset\tS08R01.txt is labelled\n",
      "\n",
      "S09\n",
      "S09R01.txt  is read\tAdding S09R01.txt to dataset\tS09R01.txt is labelled\n",
      "\n",
      "S10\n",
      "S10R01.txt  is read\t\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "data_path = './dataset/'\n",
    "\n",
    "people = []\n",
    "dataset = pd.DataFrame()\n",
    "for person in os.listdir(data_path):#返回指定路径下的文件夹\n",
    "    if '.txt' in person: \n",
    "        people.append(person)\n",
    "        \n",
    "window_length = 2\n",
    "for person in people: \n",
    "    name = person.split('R')[0]#分割R次并取序列为0的项\n",
    "    print (name)\n",
    "    file = data_path+'/'+person\n",
    "    temp = pd.read_csv(file,delimiter= \" \", header = None)\n",
    "    print (person,' is read',end = '\\t')\n",
    "    if 2 in temp[max(temp.columns)].unique():\n",
    "        print ('Adding {} to dataset'.format(person),end = '\\t')#将人加入到dataset中\n",
    "        temp.columns = ['time','A_F','A_V','A_L','L_F','L_V','L_L','T_F','T_V','T_L','Action']    \n",
    "        temp = label_prefog(temp,window_length).reset_index(drop=True)\n",
    "        temp['name'] = name\n",
    "        print ('{} is labelled'.format(person))#不指定位置，打印人名\n",
    "        dataset = pd.concat([dataset,temp],axis = 0)#数据的拼接，在axis在行上拼接，=1在列上拼接\n",
    "\n",
    "    print ('')\n",
    "dataset.reset_index(drop =True,inplace=True) #重新排列顺序\n",
    "to_path = './'\n",
    "to_name = to_path +'win_'+str(window_length)+\".csv\"\n",
    "\n",
    "dataset.to_csv(to_name,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_window(act, window_length, dataframe):\n",
    "    indices = list(dataframe[dataframe.Action == act].index)\n",
    "    groups = []\n",
    "    temp = []\n",
    "    group_count = 0\n",
    "    for i in range(len(indices)):\n",
    "        if i == len(indices) - 1:\n",
    "            temp.append(indices[i])\n",
    "            groups.append(temp)\n",
    "            temp = []\n",
    "            break\n",
    "        temp.append(indices[i])\n",
    "        if indices[i] + 1 != indices[i + 1]:\n",
    "            group_count += 1\n",
    "            groups.append(temp)\n",
    "            temp = []\n",
    "\n",
    "    fs = 64\n",
    "\n",
    "    final_dataframe = pd.DataFrame()\n",
    "    for i in groups:\n",
    "        required = math.floor(len(i) / (window_length * fs))\n",
    "\n",
    "        req_index = i[0:(required * window_length * fs)]\n",
    "\n",
    "        final_dataframe = pd.concat([final_dataframe, dataframe.iloc[req_index, :]], axis=0)\n",
    "    return final_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sbj_df(df, sbj='S01'):\n",
    "    DF0 = create_window(0, 2, df)\n",
    "    DF0 = DF0[DF0['name'] == sbj]\n",
    "    DF1 = create_window(1, 2, df)\n",
    "    DF1 = DF1[DF1['name'] == sbj]\n",
    "    DF2 = create_window(2, 2, df)\n",
    "    DF2 = DF2[DF2['name'] == sbj]\n",
    "    return DF0, DF1, DF2\n",
    "\n",
    "\n",
    "def gtda(dataframe, w=128):\n",
    "    all_data = []\n",
    "    dataframe = dataframe.drop(columns=['time', 'Action', 'name'])\n",
    "    for i in range(0, len(dataframe), w):\n",
    "        data = dataframe.iloc[i:i + w]\n",
    "        data = data.to_numpy().transpose()\n",
    "        if data.shape[1] == w:\n",
    "            all_data.append(data)\n",
    "    all_data = np.array(all_data)\n",
    "    steps = [TakensEmbedding(time_delay=5, dimension=3),\n",
    "             VietorisRipsPersistence(),\n",
    "             Scaler()\n",
    "             ]\n",
    "    tda_pipe = make_pipeline(*steps)\n",
    "    diagrams = tda_pipe.fit_transform(all_data)\n",
    "    BC = BettiCurve(n_bins=50).fit_transform(diagrams)\n",
    "    PL = PersistenceLandscape(n_bins=50).fit_transform(diagrams)\n",
    "    SL = Silhouette(n_bins=50).fit_transform(diagrams)\n",
    "\n",
    "    return np.mean(BC, axis=1), np.mean(PL, axis=1), np.mean(SL, axis=1)\n",
    "\n",
    "\n",
    "def training(x, y, sbj_name):\n",
    "    y = np.array(y)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, shuffle=True)\n",
    "    model = RandomForestClassifier(random_state=1)\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pre = model.predict(x_test)\n",
    "    print(classification_report(y_test, y_pre, digits=4))\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, y_pre)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    print('AUC:', roc_auc)\n",
    "    print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_random_list(start, stop, n):\n",
    "    '''\n",
    "    生成范围在[start,stop], 长度为n的数组.\n",
    "    区间包含左右endpoint\n",
    "    '''\n",
    "    arr = list(range(start, stop + 1))\n",
    "    shuffle_n(arr, n)\n",
    "    return arr[-n:]\n",
    "\n",
    "\n",
    "def shuffle_n(arr, n):\n",
    "    random.seed(time.time())\n",
    "    for i in range(len(arr) - 1, len(arr) - n - 1, -1):\n",
    "        j = random.randint(0, i)\n",
    "        arr[i], arr[j] = arr[j], arr[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S01\n",
      "{length} feature:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.7857    0.8800        14\n",
      "           1     0.7692    1.0000    0.8696        10\n",
      "\n",
      "    accuracy                         0.8750        24\n",
      "   macro avg     0.8846    0.8929    0.8748        24\n",
      "weighted avg     0.9038    0.8750    0.8757        24\n",
      "\n",
      "AUC: 0.8928571428571428\n",
      "\n",
      "\n",
      "{length} feature:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9000    0.8182    0.8571        11\n",
      "           1     0.8571    0.9231    0.8889        13\n",
      "\n",
      "    accuracy                         0.8750        24\n",
      "   macro avg     0.8786    0.8706    0.8730        24\n",
      "weighted avg     0.8768    0.8750    0.8743        24\n",
      "\n",
      "AUC: 0.8706293706293706\n",
      "\n",
      "\n",
      "{length} feature:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.8824    0.9375        17\n",
      "           1     0.7778    1.0000    0.8750         7\n",
      "\n",
      "    accuracy                         0.9167        24\n",
      "   macro avg     0.8889    0.9412    0.9062        24\n",
      "weighted avg     0.9352    0.9167    0.9193        24\n",
      "\n",
      "AUC: 0.9411764705882353\n",
      "\n",
      "\n",
      "feature union\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9889    0.9963    0.9926       269\n",
      "           1     0.8571    0.6667    0.7500         9\n",
      "\n",
      "    accuracy                         0.9856       278\n",
      "   macro avg     0.9230    0.8315    0.8713       278\n",
      "weighted avg     0.9847    0.9856    0.9847       278\n",
      "\n",
      "AUC: 0.8314745972738538\n",
      "\n",
      "\n",
      "S02\n",
      "{length} feature:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9545    0.7500    0.8400        28\n",
      "           1     0.7308    0.9500    0.8261        20\n",
      "\n",
      "    accuracy                         0.8333        48\n",
      "   macro avg     0.8427    0.8500    0.8330        48\n",
      "weighted avg     0.8613    0.8333    0.8342        48\n",
      "\n",
      "AUC: 0.85\n",
      "\n",
      "\n",
      "{length} feature:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6818    0.7500    0.7143        20\n",
      "           1     0.8077    0.7500    0.7778        28\n",
      "\n",
      "    accuracy                         0.7500        48\n",
      "   macro avg     0.7448    0.7500    0.7460        48\n",
      "weighted avg     0.7552    0.7500    0.7513        48\n",
      "\n",
      "AUC: 0.75\n",
      "\n",
      "\n",
      "{length} feature:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7273    0.6667    0.6957        24\n",
      "           1     0.6923    0.7500    0.7200        24\n",
      "\n",
      "    accuracy                         0.7083        48\n",
      "   macro avg     0.7098    0.7083    0.7078        48\n",
      "weighted avg     0.7098    0.7083    0.7078        48\n",
      "\n",
      "AUC: 0.7083333333333334\n",
      "\n",
      "\n",
      "feature union\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9482    0.9786    0.9632       187\n",
      "           1     0.6923    0.4737    0.5625        19\n",
      "\n",
      "    accuracy                         0.9320       206\n",
      "   macro avg     0.8202    0.7261    0.7628       206\n",
      "weighted avg     0.9246    0.9320    0.9262       206\n",
      "\n",
      "AUC: 0.7261469180973824\n",
      "\n",
      "\n",
      "S03\n",
      "{length} feature:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9189    0.9444    0.9315        36\n",
      "           1     0.9412    0.9143    0.9275        35\n",
      "\n",
      "    accuracy                         0.9296        71\n",
      "   macro avg     0.9300    0.9294    0.9295        71\n",
      "weighted avg     0.9299    0.9296    0.9295        71\n",
      "\n",
      "AUC: 0.9293650793650793\n",
      "\n",
      "\n",
      "{length} feature:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9231    0.9474    0.9351        38\n",
      "           1     0.9375    0.9091    0.9231        33\n",
      "\n",
      "    accuracy                         0.9296        71\n",
      "   macro avg     0.9303    0.9282    0.9291        71\n",
      "weighted avg     0.9298    0.9296    0.9295        71\n",
      "\n",
      "AUC: 0.9282296650717704\n",
      "\n",
      "\n",
      "{length} feature:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8837    0.9744    0.9268        39\n",
      "           1     0.9643    0.8438    0.9000        32\n",
      "\n",
      "    accuracy                         0.9155        71\n",
      "   macro avg     0.9240    0.9091    0.9134        71\n",
      "weighted avg     0.9200    0.9155    0.9147        71\n",
      "\n",
      "AUC: 0.9090544871794872\n",
      "\n",
      "\n",
      "feature union\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9700    1.0000    0.9848       194\n",
      "           1     1.0000    0.8696    0.9302        46\n",
      "\n",
      "    accuracy                         0.9750       240\n",
      "   macro avg     0.9850    0.9348    0.9575       240\n",
      "weighted avg     0.9758    0.9750    0.9743       240\n",
      "\n",
      "AUC: 0.9347826086956521\n",
      "\n",
      "\n",
      "S05\n",
      "{length} feature:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9655    0.9825    0.9739        57\n",
      "           1     0.9846    0.9697    0.9771        66\n",
      "\n",
      "    accuracy                         0.9756       123\n",
      "   macro avg     0.9751    0.9761    0.9755       123\n",
      "weighted avg     0.9758    0.9756    0.9756       123\n",
      "\n",
      "AUC: 0.9760765550239234\n",
      "\n",
      "\n",
      "{length} feature:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9219    0.9672    0.9440        61\n",
      "           1     0.9661    0.9194    0.9421        62\n",
      "\n",
      "    accuracy                         0.9431       123\n",
      "   macro avg     0.9440    0.9433    0.9431       123\n",
      "weighted avg     0.9442    0.9431    0.9431       123\n",
      "\n",
      "AUC: 0.9432839767318879\n",
      "\n",
      "\n",
      "{length} feature:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8841    0.9839    0.9313        62\n",
      "           1     0.9815    0.8689    0.9217        61\n",
      "\n",
      "    accuracy                         0.9268       123\n",
      "   macro avg     0.9328    0.9264    0.9265       123\n",
      "weighted avg     0.9324    0.9268    0.9266       123\n",
      "\n",
      "AUC: 0.9263617133791644\n",
      "\n",
      "\n",
      "feature union\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9672    1.0000    0.9833       236\n",
      "           1     1.0000    0.8644    0.9273        59\n",
      "\n",
      "    accuracy                         0.9729       295\n",
      "   macro avg     0.9836    0.9322    0.9553       295\n",
      "weighted avg     0.9738    0.9729    0.9721       295\n",
      "\n",
      "AUC: 0.9322033898305084\n",
      "\n",
      "\n",
      "S06\n",
      "{length} feature:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        18\n",
      "           1     1.0000    1.0000    1.0000        18\n",
      "\n",
      "    accuracy                         1.0000        36\n",
      "   macro avg     1.0000    1.0000    1.0000        36\n",
      "weighted avg     1.0000    1.0000    1.0000        36\n",
      "\n",
      "AUC: 1.0\n",
      "\n",
      "\n",
      "{length} feature:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        17\n",
      "           1     1.0000    1.0000    1.0000        19\n",
      "\n",
      "    accuracy                         1.0000        36\n",
      "   macro avg     1.0000    1.0000    1.0000        36\n",
      "weighted avg     1.0000    1.0000    1.0000        36\n",
      "\n",
      "AUC: 1.0\n",
      "\n",
      "\n",
      "{length} feature:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9500    1.0000    0.9744        19\n",
      "           1     1.0000    0.9412    0.9697        17\n",
      "\n",
      "    accuracy                         0.9722        36\n",
      "   macro avg     0.9750    0.9706    0.9720        36\n",
      "weighted avg     0.9736    0.9722    0.9722        36\n",
      "\n",
      "AUC: 0.9705882352941176\n",
      "\n",
      "\n",
      "feature union\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9870    1.0000    0.9934       227\n",
      "           1     1.0000    0.8636    0.9268        22\n",
      "\n",
      "    accuracy                         0.9880       249\n",
      "   macro avg     0.9935    0.9318    0.9601       249\n",
      "weighted avg     0.9881    0.9880    0.9876       249\n",
      "\n",
      "AUC: 0.9318181818181819\n",
      "\n",
      "\n",
      "S07\n",
      "{length} feature:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.7000    0.8235        10\n",
      "           1     0.7000    1.0000    0.8235         7\n",
      "\n",
      "    accuracy                         0.8235        17\n",
      "   macro avg     0.8500    0.8500    0.8235        17\n",
      "weighted avg     0.8765    0.8235    0.8235        17\n",
      "\n",
      "AUC: 0.85\n",
      "\n",
      "\n",
      "{length} feature:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000         5\n",
      "           1     1.0000    1.0000    1.0000        12\n",
      "\n",
      "    accuracy                         1.0000        17\n",
      "   macro avg     1.0000    1.0000    1.0000        17\n",
      "weighted avg     1.0000    1.0000    1.0000        17\n",
      "\n",
      "AUC: 1.0\n",
      "\n",
      "\n",
      "{length} feature:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        11\n",
      "           1     1.0000    1.0000    1.0000         6\n",
      "\n",
      "    accuracy                         1.0000        17\n",
      "   macro avg     1.0000    1.0000    1.0000        17\n",
      "weighted avg     1.0000    1.0000    1.0000        17\n",
      "\n",
      "AUC: 1.0\n",
      "\n",
      "\n",
      "feature union\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000       225\n",
      "           1     1.0000    1.0000    1.0000        10\n",
      "\n",
      "    accuracy                         1.0000       235\n",
      "   macro avg     1.0000    1.0000    1.0000       235\n",
      "weighted avg     1.0000    1.0000    1.0000       235\n",
      "\n",
      "AUC: 1.0\n",
      "\n",
      "\n",
      "S08\n",
      "{length} feature:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7879    0.7879    0.7879        33\n",
      "           1     0.7083    0.7083    0.7083        24\n",
      "\n",
      "    accuracy                         0.7544        57\n",
      "   macro avg     0.7481    0.7481    0.7481        57\n",
      "weighted avg     0.7544    0.7544    0.7544        57\n",
      "\n",
      "AUC: 0.7481060606060607\n",
      "\n",
      "\n",
      "{length} feature:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6774    0.7500    0.7119        28\n",
      "           1     0.7308    0.6552    0.6909        29\n",
      "\n",
      "    accuracy                         0.7018        57\n",
      "   macro avg     0.7041    0.7026    0.7014        57\n",
      "weighted avg     0.7046    0.7018    0.7012        57\n",
      "\n",
      "AUC: 0.7025862068965517\n",
      "\n",
      "\n",
      "{length} feature:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7333    0.7586    0.7458        29\n",
      "           1     0.7407    0.7143    0.7273        28\n",
      "\n",
      "    accuracy                         0.7368        57\n",
      "   macro avg     0.7370    0.7365    0.7365        57\n",
      "weighted avg     0.7370    0.7368    0.7367        57\n",
      "\n",
      "AUC: 0.7364532019704433\n",
      "\n",
      "\n",
      "feature union\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8642    0.8140    0.8383        86\n",
      "           1     0.4839    0.5769    0.5263        26\n",
      "\n",
      "    accuracy                         0.7589       112\n",
      "   macro avg     0.6740    0.6954    0.6823       112\n",
      "weighted avg     0.7759    0.7589    0.7659       112\n",
      "\n",
      "AUC: 0.695438282647585\n",
      "\n",
      "\n",
      "S09\n",
      "{length} feature:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9444    0.9714    0.9577        35\n",
      "           1     0.9737    0.9487    0.9610        39\n",
      "\n",
      "    accuracy                         0.9595        74\n",
      "   macro avg     0.9591    0.9601    0.9594        74\n",
      "weighted avg     0.9599    0.9595    0.9595        74\n",
      "\n",
      "AUC: 0.96007326007326\n",
      "\n",
      "\n",
      "{length} feature:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9688    0.9394    0.9538        33\n",
      "           1     0.9524    0.9756    0.9639        41\n",
      "\n",
      "    accuracy                         0.9595        74\n",
      "   macro avg     0.9606    0.9575    0.9589        74\n",
      "weighted avg     0.9597    0.9595    0.9594        74\n",
      "\n",
      "AUC: 0.9575018477457502\n",
      "\n",
      "\n",
      "{length} feature:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9524    0.9524    0.9524        42\n",
      "           1     0.9375    0.9375    0.9375        32\n",
      "\n",
      "    accuracy                         0.9459        74\n",
      "   macro avg     0.9449    0.9449    0.9449        74\n",
      "weighted avg     0.9459    0.9459    0.9459        74\n",
      "\n",
      "AUC: 0.9449404761904762\n",
      "\n",
      "\n",
      "feature union\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9859    0.9906    0.9882       212\n",
      "           1     0.9500    0.9268    0.9383        41\n",
      "\n",
      "    accuracy                         0.9802       253\n",
      "   macro avg     0.9680    0.9587    0.9633       253\n",
      "weighted avg     0.9801    0.9802    0.9801       253\n",
      "\n",
      "AUC: 0.9586976530142659\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subject_list = ['S01', 'S02', 'S03', 'S05', 'S06', 'S07', 'S08', 'S09']\n",
    "df = pd.read_csv('./win_2.csv')\n",
    "for sbj in subject_list:\n",
    "    DF0, DF1, DF2 = sbj_df(df, sbj=sbj)\n",
    "    NOR_DF = pd.concat([DF0, DF2])\n",
    "    nor_bc, nor_pl, nor_sl = gtda(NOR_DF)\n",
    "    fog_bc, fog_pl, fog_sl = gtda(DF1)\n",
    "\n",
    "    fog = [fog_bc, fog_pl, fog_sl]\n",
    "    normal = [nor_bc, nor_pl, nor_sl]\n",
    "    print(sbj)\n",
    "\n",
    "    for length, nor_feature in enumerate(normal):\n",
    "        print('{length} feature:')\n",
    "        fog_feature = fog[length]\n",
    "        idx = get_random_list(0, len(nor_feature) - 1, int(len(fog_feature) * 1))\n",
    "        nor_feature = nor_feature[idx]\n",
    "\n",
    "        X = np.concatenate([nor_feature, fog_feature], axis=0)\n",
    "        Y = []\n",
    "        Y += len(nor_feature) * [0]\n",
    "        Y += len(fog_feature) * [1]\n",
    "\n",
    "        # x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, shuffle=True)\n",
    "        training(X, Y, sbj)\n",
    "\n",
    "    all_fog = np.concatenate(fog, axis=1)\n",
    "    all_nor = np.concatenate(normal, axis=1)\n",
    "    all_X = np.concatenate([all_nor, all_fog], axis=0)\n",
    "    all_Y = []\n",
    "    all_Y += len(all_nor) * [0]\n",
    "    all_Y += len(all_fog) * [1]\n",
    "    print('feature union')\n",
    "    training(all_X, all_Y, sbj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
